import streamlit as st
import pandas as pd
import jdatetime
import datetime
from google.cloud import bigquery

# ====== ØªÙ†Ø¸ÛŒÙ… Ú©Ù„ÛŒØ¯ Ø³Ø±ÙˆÛŒØ³ ======
credentials_info = dict(st.secrets["gcp_service_account"])
client = bigquery.Client.from_service_account_info(credentials_info)

# ====== ØªÙ†Ø¸ÛŒÙ… Ø¸Ø§Ù‡Ø± ======
st.set_page_config(page_title="Service Report Processor", layout="centered")
st.title("ğŸ“Š Ú©Ø§Ø± Ø±Ùˆ Ø¨Ù‡ Ú©Ø§Ø±Ø¯Ø§Ù† Ø¨Ø³Ù¾Ø§Ø±")

# ====== Ù„ÛŒØ³Øª Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ ======
table_names = [
    "hspdata",
    "hspdata_02",
    "hspdata_ghor",
    "hspdata_ac",
    "test"
]

selected_table_name = st.selectbox("âœ… Ù†Ø§Ù… Ø¬Ø¯ÙˆÙ„ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", table_names)

# ====== Ù†Ø§Ù… Ø¯Ù‚ÛŒÙ‚ ÙÛŒÙ„Ø¯Ù‡Ø§ Ø·Ø¨Ù‚ Ø¬Ø¯ÙˆÙ„ BigQuery ======
expected_columns = [
    "CreatDate",
    "UserServiceId",
    "Creator",
    "ServiceName",
    "Username",
    "ServiceStatus",
    "ServicePrice",
    "Package",
    "StartDate",
    "EndDate"
]

# ====== Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ ======
if selected_table_name:
    table_path = f"frsphotspots.HSP.{selected_table_name}"
    query = f"SELECT MAX(UserServiceId) as max_usv FROM `{table_path}`"
    try:
        result = client.query(query).result()
        max_usv = next(result)['max_usv'] or 0
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† UserServiceId Ø§Ø² Ø¨ÛŒÚ¯â€ŒÚ©ÙˆØ¦Ø±ÛŒ: {e}")
        max_usv = 0

    st.number_input(
        "ğŸ”¢ Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† UserServiceId Ù…ÙˆØ¬ÙˆØ¯:",
        min_value=0,
        value=int(max_usv),
        step=1,
        key="readonly_usv",
        disabled=True
    )
    ronumber = max_usv

    # ====== Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ======
    uploaded_file = st.file_uploader("ğŸ“ ÙØ§ÛŒÙ„ CSV Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯", type=["csv"])

    if uploaded_file is not None:
        df_raw = pd.read_csv(uploaded_file)

        # ====== Ø­Ø°Ù Ø³ØªÙˆÙ† Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø§Ú¯Ø± Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø³ØªÙˆÙ† Ø¢Ù…Ø¯Ù‡ ======
        if df_raw.columns[0].lower() not in ["cdt", "creatdate"]:
            df_raw = df_raw.iloc[:, 1:]

        # ====== ØªØºÛŒÛŒØ± Ù†Ø§Ù… Ø¨Ø¹Ø¶ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ ======
        rename_map = {
            "CDT": "CreatDate",
            "SavingOffUsed": "Package"
        }
        df = df_raw.rename(columns=rename_map).copy()

        # ====== Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± ======
        clean_df = pd.DataFrame()
        for col in expected_columns:
            if col in df.columns:
                clean_df[col] = df[col]
            else:
                clean_df[col] = None

        # ====== ØªØ¨Ø¯ÛŒÙ„ CreatDate Ø¨Ù‡ Ù…ÛŒÙ„Ø§Ø¯ÛŒ ======
        def to_gregorian_if_jalali(date_str):
            try:
                if not isinstance(date_str, str):
                    return date_str
                if date_str.startswith('14'):
                    parts = date_str.replace('-', '/').split('/')
                    if len(parts) == 3:
                        jy, jm, jd = map(int, parts)
                        gdate = jdatetime.date(jy, jm, jd).togregorian()
                        return gdate.strftime('%Y-%m-%d')
                elif date_str.startswith('20'):
                    parts = date_str.replace('-', '/').split('/')
                    if len(parts) == 3:
                        gy, gm, gd = map(int, parts)
                        return datetime.date(gy, gm, gd).strftime('%Y-%m-%d')
                return date_str
            except:
                return date_str

        clean_df['CreatDate'] = clean_df['CreatDate'].astype(str).str.split().str[0]
        clean_df['CreatDate'] = clean_df['CreatDate'].apply(to_gregorian_if_jalali)

        # ====== ØªØ¨Ø¯ÛŒÙ„ UserServiceId Ø¨Ù‡ Ø¹Ø¯Ø¯ ======
        clean_df['UserServiceId'] = pd.to_numeric(clean_df['UserServiceId'], errors='coerce')

        # ====== Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ ======
        clean_df = clean_df[clean_df['UserServiceId'] > ronumber].reset_index(drop=True)

        # ====== Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ ======
        st.success("âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. Ø¯Ø§Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ:")
        st.dataframe(clean_df)

        # ====== Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ BigQuery ======
        if st.button("ğŸš€ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ø¨ÛŒÚ¯â€ŒÚ©ÙˆØ¦Ø±ÛŒ"):
            try:
                job_config = bigquery.LoadJobConfig(
                    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,
                    source_format=bigquery.SourceFormat.CSV,
                    skip_leading_rows=0,
                    schema=[
                        bigquery.SchemaField("CreatDate", "DATE"),
                        bigquery.SchemaField("UserServiceId", "INTEGER"),
                        bigquery.SchemaField("Creator", "STRING"),
                        bigquery.SchemaField("ServiceName", "STRING"),
                        bigquery.SchemaField("Username", "STRING"),
                        bigquery.SchemaField("ServiceStatus", "STRING"),
                        bigquery.SchemaField("ServicePrice", "FLOAT"),
                        bigquery.SchemaField("Package", "FLOAT"),
                        bigquery.SchemaField("StartDate", "STRING"),
                        bigquery.SchemaField("EndDate", "STRING"),
                    ],
                )
                job = client.load_table_from_dataframe(clean_df, table_path, job_config=job_config)
                job.result()

                st.success(f"âœ… Ø§Ø±Ø³Ø§Ù„ Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯! ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙ Ø§ÙØ²ÙˆØ¯Ù‡â€ŒØ´Ø¯Ù‡: {len(clean_df)}")

                if st.button("ğŸ  Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ø®Ø§Ù†Ù‡"):
                    st.experimental_rerun()

            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ø¨ÛŒÚ¯â€ŒÚ©ÙˆØ¦Ø±ÛŒ:\n\n{e}")

import streamlit as st
import pandas as pd
import jdatetime
import datetime
import numpy as np
from google.cloud import bigquery

st.set_page_config(page_title="BigQuery Uploader", layout="centered")
st.title("ğŸ“Š Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ BigQuery")

# --- Ø§ØªØµØ§Ù„ Ø¨Ù‡ BigQuery ---
credentials_info = dict(st.secrets["gcp_service_account"])
client = bigquery.Client.from_service_account_info(credentials_info)

# --- Ø§Ù†ØªØ®Ø§Ø¨ Ø¬Ø¯ÙˆÙ„ ---
table_names = [
    "hspdata",
    "hspdata_02",
    "hspdata_ghor",
    "hspdata_ac",
    "test"
]
selected_table_name = st.selectbox("âœ… Ù†Ø§Ù… Ø¬Ø¯ÙˆÙ„ Ù…Ù‚ØµØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", table_names)
table_path = f"frsphotspots.HSP.{selected_table_name}"

# --- Ú¯Ø±ÙØªÙ† max_usv ---
max_usv = 0
query = f"SELECT MAX(UserServiceId) as max_usv FROM `{table_path}`"
try:
    result = client.query(query).result()
    max_usv = next(result)['max_usv'] or 0
except Exception as e:
    st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† UserServiceId: {e}")
st.info(f"Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† UserServiceId ÙØ¹Ù„ÛŒ: {max_usv}")

# --- Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ CSV ---
uploaded_file = st.file_uploader("ğŸ”½ ÙØ§ÛŒÙ„ CSV Ø®Ø§Ù… Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯", type=['csv'])

if uploaded_file:
    df_raw = pd.read_csv(uploaded_file)

    columns_to_drop = [
        'PayPlan', 'DirectOff', 'VAT', 'PayPrice', 'Off', 'SavingOff',
        'CancelDT', 'ReturnPrice', 'InstallmentNo', 'InstallmentPeriod',
        'InstallmentFirstCash', 'ServiceIsDel'
    ]
    df_clean = df_raw.drop(columns=columns_to_drop, errors='ignore')

    # Ø§Ù†ØªÙ‚Ø§Ù„ Ø³ØªÙˆÙ† ØªØ§Ø±ÛŒØ® "CDT" Ø¨Ù‡ Ø§ÙˆÙ„ Ø¬Ø¯ÙˆÙ„ (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´Øª)
    cols = list(df_clean.columns)
    if "CDT" in cols:
        cols.insert(0, cols.pop(cols.index("CDT")))
        df_clean = df_clean[cols]

    new_columns = [
        "CreatDate",
        "UserServiceId",
        "Creator",
        "ServiceName",
        "Username",
        "ServiceStatus",
        "ServicePrice",
        "Package",
        "StartDate",
        "EndDate"
    ]
    df_clean.columns = new_columns[:len(df_clean.columns)]

    # ÙÙ‚Ø· Ø¨Ø®Ø´ ØªØ§Ø±ÛŒØ® Ø±Ø§ Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø±
    df_clean['CreatDate'] = df_clean['CreatDate'].astype(str).str.split().str[0]

    def to_gregorian_if_jalali(date_str):
        try:
            if not isinstance(date_str, str):
                return date_str
            if date_str.startswith('14'):
                parts = date_str.replace('-', '/').split('/')
                if len(parts) == 3:
                    jy, jm, jd = map(int, parts)
                    gdate = jdatetime.date(jy, jm, jd).togregorian()
                    return gdate.strftime('%Y-%m-%d')
            elif date_str.startswith('20'):
                parts = date_str.replace('-', '/').split('/')
                if len(parts) == 3:
                    gy, gm, gd = map(int, parts)
                    return datetime.date(gy, gm, gd).strftime('%Y-%m-%d')
            return date_str
        except Exception:
            return date_str

    df_clean['CreatDate'] = df_clean['CreatDate'].apply(to_gregorian_if_jalali)

    # Ù…Ù‚Ø§Ø¯ÛŒØ± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ServicePrice Ùˆ Package Ú©Ø§Ù…Ù„Ø§Ù‹ Ø®Ø§Ù„ÛŒ
    df_clean['ServicePrice'] = np.nan
    df_clean['Package'] = np.nan

    for col in ['Creator', 'ServiceName', 'Username', 'ServiceStatus', 'StartDate', 'EndDate']:
        df_clean[col] = df_clean[col].replace({None: '', 'None': '', 'nan': '', 'NaN': '', np.nan: ''})

    df_clean['UserServiceId'] = pd.to_numeric(df_clean['UserServiceId'], errors='coerce')
    df_clean = df_clean[df_clean['UserServiceId'] > max_usv].reset_index(drop=True)

    st.info(f"ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙ Ù‚Ø§Ø¨Ù„ Ø¢Ù¾Ù„ÙˆØ¯: {len(df_clean)}")
    st.dataframe(df_clean)

    if len(df_clean) == 0:
        st.warning("Ø¯ÛŒØªØ§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    else:
        if st.button("ğŸš€ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ BigQuery"):
            # ØªØ¨Ø¯ÛŒÙ„ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø³Ø§Ù„
            df_clean['CreatDate'] = pd.to_datetime(df_clean['CreatDate'], errors='coerce').dt.date
            df_clean['UserServiceId'] = pd.to_numeric(df_clean['UserServiceId'], errors='coerce').astype('Int64')
            df_clean['ServicePrice'] = pd.to_numeric(df_clean['ServicePrice'], errors='coerce')
            df_clean['Package'] = pd.to_numeric(df_clean['Package'], errors='coerce')
            for col in ['Creator', 'ServiceName', 'Username', 'ServiceStatus', 'StartDate', 'EndDate']:
                df_clean[col] = df_clean[col].astype(str)

            job_config = bigquery.LoadJobConfig(
                write_disposition=bigquery.WriteDisposition.WRITE_APPEND,
                source_format=bigquery.SourceFormat.CSV,
                skip_leading_rows=0,
                schema=[
                    bigquery.SchemaField("CreatDate", "DATE"),
                    bigquery.SchemaField("UserServiceId", "INTEGER"),
                    bigquery.SchemaField("Creator", "STRING"),
                    bigquery.SchemaField("ServiceName", "STRING"),
                    bigquery.SchemaField("Username", "STRING"),
                    bigquery.SchemaField("ServiceStatus", "STRING"),
                    bigquery.SchemaField("ServicePrice", "FLOAT"),
                    bigquery.SchemaField("Package", "FLOAT"),
                    bigquery.SchemaField("StartDate", "STRING"),
                    bigquery.SchemaField("EndDate", "STRING"),
                ]
            )

            try:
                job = client.load_table_from_dataframe(df_clean, table_path, job_config=job_config)
                job.result()
                st.success(f"âœ… Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ BigQuery Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§: {len(df_clean)}")
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ Ø¨ÛŒÚ¯â€ŒÚ©ÙˆØ¦Ø±ÛŒ:\n{e}")
